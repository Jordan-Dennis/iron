\documentclass[a4paper, twocolumn]{article}
\setlength{\textwidth}{180mm}
\setlength{\textheight}{250mm}
\setlength{\parindent}{0mm}
\setlength{\parskip}{2mm}
\setlength{\oddsidemargin}{15mm}
\setlength{\hoffset}{-1in}
\setlength{\topmargin}{-2.5pc}
\setlength{\headsep}{20pt}
\setlength{\columnsep}{4mm}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage{caption}
\usepackage{listings}
\lstset{
    language=C, 
    literate={\ \ }{{\ }}1, 
    keywordstyle=\bfseries, 
    basicstyle=\ttfamily}
\def\ttdefault{pcr}
\def\citation{{\bfseries (Annon, dd/mm/yyyy)}}
\begin{document}
\section*{Foreword}
I used the \verb!c! programming language to complete this task. I %
represented the system of spins as a \verb!struct!, %
defined below in one dimension. 

\begin{lstlisting}
typedef struct ising_t
{
    float epsilon;
    float magnetic_field;
    float epsilon;
    int length;
    int *ensemble;
} ising_t;
\end{lstlisting}

Scaling this to two dimensions was more difficult because the %
\verb!*ensemble! had to be transformed into \verb!**ensemble!. %
It is possible to implement this in a single \verb!struct! %
using \verb!union ensemble {int *1d, int **2d};!, but in the %
code available on my \verb!github! I have used two separate %
\verb!struct!s resulting in code duplication for many of the %
methods. I made this descision because I had not used \verb!c! %
prior to this project and was unaware of the \verb!union! %
keyword and its uses. I am describing this because you may %
notice discrepancies in the code snippets that I have include %
where \verb!int *(*)ensemble = system -> ensemble;! is invoked %
to access the array of spins. 


\subsection*{Question 1 a)}
I selected three different temperatures, \(1.0, 2.0\) and %
\(3.0 \epsilon / k\), and ran the metropolis algorithm for %
\(1000N\) steps. At each of these temperatures the system %
was initialised in a random state and allowed to equilibrate. 

\begin{centering}
    \includegraphics%
        [width=0.5\textwidth]%
        {pub/figures/first_and_last_ising_1d.pdf}
    \captionof{figure}[]{Each vertical pair of lines %
        represents the spin state. The top one is %
        the random initial state and the bottom one %
        is the equilibrated final state.}
    \label{fig:1}
\end{centering}

We noticed that at lower temperatures the spin chunks were %
much larger than at higher temperatures. This is particularly %
pronounced between the \(T = 3.0\epsilon/k\) and \(T = %
1.0\epsilon/k\) plots in figure \ref{fig:1}. To evolve the %
system we used the version of the metropolis algorithm %
shown below, 

\begin{lstlisting}
/*
 * metropolis_step
 * ------------------------ 
 * Evolve the system by attempting to 
 * flip a spin. The step is weighted 
 * by the Boltzmann factor.
 *
 * parameters
 * ----------
 * ising_t *system: A struct 
 *     enscapulating the information 
 *     related to the system. 
 */
void metropolis_step(ising_t *system)
{
    float temp = system -> temperature;
    int *ensemble = system -> ensemble;
    int length = system -> length;
    int spin = random_index(length);
    int change = 2*ensemble[spin]*(
        ensemble[modulo(spin+1,length)] +
        ensemble[modulo(spin-1,length)]);

    if ((change < 0)
        || (exp(-change/temp)>randn()))
    {
        ensemble[spin] *= -1;
    }
}
\end{lstlisting}

where, \verb!rand! generates a random number in the range %
\([0, 1]\), and \verb!modulo! is modified to produce %
positive input on negative numbers like the \verb!python! %
implmentation. This is not the native \verb!c! implementation. %
I used the \verb!||! short circuit operator so that %
the second comparison was not evaluated on every call %
to the function. 
            

\subsection*{Question 1 b)}
I found that it was worth considering what the \emph{basic %
unit} of the Ising model was. In the absence of an external %
magnetic field the energy is a function of the pairs. I start %
by considering the partition function of an individual pair. %
This is a two level system; either the pair are aligned or they %
are anti-aligned with the corresponding energies.
%
\begin{align}
    Z_{i} &= \sum_{s_{i} = \pm 1}
            \exp\left(-\frac{\varepsilon s_{i}s_{i+1}}{\tau}\right)
            \nonumber\\
        &= \exp\left(-\frac{\varepsilon}{\tau}\right) +
            \exp\left(\frac{\varepsilon}{\tau}\right)
            \nonumber\\
        &= 2\cosh\left(\frac{\varepsilon}{\tau}\right).
    \label{eqn:1}
\end{align}


Similarly to the para-magnetic case we can multiply the system %
partition functions of single constituents together to get the %
partition function of the entire system. However, the condition %
to do this was that the constiutuents were independent, but the %
Ising model contains interactions. In the case of the Ising model %
the constituents that are independent are the pairs, not the %
individual spins. You may think think then that we only consider %
\(N / 2\) unique pairs but this is not the case. In a chain each %
spin is counted in two pairs so the power is still \(N\). 


A small detail that I skipped was what happens at the boundary. %
The two spins on the end of the chains are not (neccessarily) %
counted twice. In the limit of a very large chain of spins we %
can see that the boundary affect will not matter however, we %
got about this nuance in a much more interesting way by considering %
cyclic boundary conditions. That is to say that the spin on the %
far end of the chain is a neighbour to the spin at the start of the %
chain and vice versa. 


Given the partition function \(Z = (2\cosh(\varepsilon / \tau))^{N}\), we 
calculated the internal energy using,

\begin{align}
    U &= \tau^{2}\partial_{\tau}\ln(Z)\label{EQN1}\\
        &= \tau^{2}\partial_{\tau}
            \ln\left(2\cosh\left(\frac{\varepsilon}{\tau}\right)^{N}\right)
            \nonumber \\
        &= N\tau^{2}\partial_{\tau}
            \ln\left(2\cosh\left(\frac{\varepsilon}{\tau}\right)\right)
            \nonumber \\
        &= N\tau^{2}\partial_{\tau}
            \left(2\cosh\left(\frac{\varepsilon}{\tau}\right)\right)
            \frac{1}{2\cosh\left(\frac{\varepsilon}{\tau}\right)}
            \nonumber \\
        &= N\tau^{2}\partial_{\tau}\left(\frac{\varepsilon}{\tau}\right)
            \frac{\sinh\left(\frac{\varepsilon}{\tau}\right)}
            {\cosh\left(\frac{\varepsilon}{\tau}\right)}\nonumber \\
        &= -\varepsilon N\tanh\left(\frac{\varepsilon}{\tau}\right)
    \label{eqn:2}.
\end{align}

We calculated the free energy of the system using,

\begin{align}
    F &= -\tau\ln Z \\
        &= -\tau\ln\left(\left(
            2\cosh\left(\frac{\varepsilon}{\tau}\right)\right)^{N}\right) 
            \nonumber \\
        &= -N\tau\ln\left(
            2\cosh\left(\frac{\varepsilon}{\tau}\right)\right) 
            \nonumber \\
        &= -N\tau\ln\left(
            \exp\left(\frac{\varepsilon}{\tau}\right) + 
            \exp\left(-\frac{\varepsilon}{\tau}\right)\right) \nonumber \\
        &= -N\tau\ln\left(\exp\left(\frac{\varepsilon}{\tau}\right)
            \left(1 + \exp\left(-2\frac{\varepsilon}{\tau}\right)\right)
            \right)\nonumber \\
        &= -N\tau\ln\left(\exp\left(\frac{\varepsilon}{\tau}\right)\right)
            - N\tau\ln\left(1 + 
            \exp\left(-2\frac{\varepsilon}{\tau}\right)\right) \nonumber \\
        &= -N\varepsilon - N\tau\ln\left(1 + 
            \exp\left(-2\frac{\varepsilon}{\tau}\right)\right)
    \label{eqn:3}. 
\end{align}

The entropy followed from the combination of Equation \ref{eqn:2} and %
Equation \ref{eqn:1} using Equation \ref{eqn:3},

\begin{align}
    \tau\sigma &= F - U\\
        &= -N\varepsilon\tanh\left(\frac{\varepsilon}{\tau}\right) + 
            N\varepsilon + N\tau\ln\left(1 + 
            \exp\left(-2\frac{\varepsilon}{\tau}\right)\right)\nonumber \\
    \sigma &= \frac{\varepsilon}{\tau}\left(1 - 
            \tanh\left(\frac{\varepsilon}{\tau}\right)\right) +
            \ln\left(1 + \exp\left(-2\frac{\varepsilon}{\tau}\right)\right)
    \label{eqn:4}.
\end{align} 

Finally, we determined the specific heat using Equation \ref{eqn:2} %
and Equation \ref{eqn:3},

\begin{align}
    C &= \partial_{\tau}U\\
        &= \partial_{\tau}\left(-N\varepsilon\tanh\left(
            \frac{\varepsilon}{\tau}\right)\right)\nonumber\\
        &= -N\varepsilon\partial_{\tau}\left(\frac{\varepsilon}{\tau}\right)
            \frac{1}{\cosh^{2}\left(\frac{\varepsilon}{\tau}\right)}
            \nonumber\\
        &= \frac{N\varepsilon^{2}}{\tau^{2}\cosh^{2}\left(
            \frac{\varepsilon}{\tau}\right)}
    \label{eqn:5}.
\end{align}    


\subsection*{Question 1 c)}
\begin{figure}[h]
    \centering
    \includegraphics%
        [width=0.5\textwidth]%
        {pub/figures/physical_parameters_ising_1d.pdf}
    \captionof{figure}[]{The top left is the energy and the %
        top right is the entropy. The bottom left is the %
        free energy and the bottom right is the heat capacity.}
    \label{fig:2}
\end{figure}        

I started by simulating a one dimensional Ising model with no %
external magnetic field, which I compared to the analytic %
expressions derived above. I used periodic boundary conditions %
and chose to implement my models using a lattice size of one-hundred %
spins. I chose to use one-hundred spins because it evaluated %
fast on my device and was large enough to be interesting. 


Starting with our one dimensional model we equilibrated the %
system for multiple different temperatures and settled on %
using \(1000N\) as the length of the loop. This was likely %
too many but I found that for low temperatures when the %
probability of a flip becomes small, a larger number of %
steps was required. 


I chose to sample the temperatures over the range \(0.0 - 4.0 %
\epsilon / k\) incrementing by \(0.2 \epsilon / k\). I %
initialised the system only once at the highest temperature %
that we sampled, \(3.8 \epsilon / k\). I equilibrated the %
system at this temperature by evolving it for \(1000N\) %
and then started to cool the system taking measurements %
at each new system. 


The alternative model was to randomly initialise the system %
at every temperature. This would require approximately %
twice the number of steps since the system would have to %
be equilibrated at every temperature. I realize that the %
cooling method has a side affect of leading to "overflow". %
By "overflow" I mean that the first few measurements of %
each temperature are slightly out of equilibrium at the %
higher temperature. 


To calculate the energy of the system I used the following %
algorithm, 

\begin{lstlisting}
/*
 * energy_ising_t
 * --------------
 * Calculate the energy of the system.
 *
 * parameters
 * ----------
 * ising_t *system: A struct 
 *     enscapulating the information 
 *     related to the system. 
 *
 * returns
 * -------
 * float energy: The energy of the
 *     system in Joules. 
 */
float energy_ising_t(ising_t *system)
{
    int length = system->length;
    int *ensemble = system->ensemble;
    float energy = 0.;

    for(int spin=0; spin<length; spin++)
    {
        energy -= ensemble[spin] *  
            ensemble[modulo(spin+1,length)];
    }

    return energy;
}
\end{lstlisting}


You may notice that I am only counting the righthand neighbour %
of each spin. I chose this method because it is more optimal. %
If I was to count each neighbour then every pair would be %
counted twice and we would have to divide the final result by %
\verb!2.!. By only counting one of the neighbours I have %
halved the number of computations. 


A pair of spins is the \emph{base unit} of the ising model %
so to calculate the entropy I counted the number of aligned %
pairs and then used the \emph{chose} function to calculate %
the multiplicity. However, it was not quite this simples %
since \(100!\) is \(\sim 10^{157}\), which overflows an %
integer in the programs memory. 


To fix this problem I used the stirling approximation to %
compute the entropy directly. This implies that the %
entropy should be less accurate at lower temperatures %
where the entropy is low and the Stirling approximation %
diverges from the actual entropy. The code that I used %
to calculate the entropy was,

\begin{lstlisting}
/*
 * entropy_ising_t
 * ---------------
 * Calculate the entropy of a 
 * configuration. 
 *
 * parameters
 * ----------
 * ising_t *system: A struct 
 *     enscapulating the information 
 *     related to the system. 
 *
 * returns
 * -------
 * float entropy: The entropy of the
 *     system in natural units. 
 */
float entropy_ising_t(ising_t *system)
{ 
    int length = system->length;
    int *ensemble = system->ensemble; 
    int up = 0;

    for (int spin=0; spin<length; spin++)
    {
        up += ensemble[spin] == 
            ensemble[modulo(spin+1,length)];
    }

    int down = length - up;

    float entropy = length * log(length) - 
        up * log(up) - down * log(down);
    
    return entropy;   
}
\end{lstlisting}


\subsection*{Question 1 d)}
Consider the energy depicted in figure \ref{fig:2}. We see that %
the energy is a decreasing function of the temperature. This %
implies that the spins tend to align as the temperature decreases. %
This makes sense because the Boltzmann factor for the lower state %
becomes more favoured. Similarly the entropy is a increasing %
function of the temperature. As the spins tend to align at lower %
temperatures the number of ways to arrange the state becomes %
smaller and hence the entropy decreasing, 
\subsection*{Question 1 e)}

        
%\newpage
%\section*{Introduction}
%The study of magnetic materials is an area of academic %
%and industrial interest \citation. For example, magnetic %
%technologies are important in the ongoing development of %
%quantum computers, superconducting circuits and other %
%examples in electronics \citation. At a fundamental level %
%magnetisation is a well understood phenomenon, yet it is %
%difficult to theoretically model. One simple model of magnetic %
%materials is the Ising model. 
%
%
%The Ising model is the simplest model of a ferro-magnet \citation. %
%Despite the simplicity of the Ising model it displays rich %
%physical behaviour and has analytic solutions in one and %
%two dimensions \citation.  The Ising model is the simplest model %
%to account for inter-molecular interactions and contain a phase %
%transition. This makes it an excellent medium for studying %
%magnetic phenomenon \citation. 
%
%
%By modifying the basic Ising model we can simulate many %
%phenomenon including glasses \citation. The Ising model %
%has broader significance and can be used to construct very %
%simple neural networks called Boltzmann machines \citation. We tested %
%one and two dimension Ising models and confirmed that they %
%matched theoretical predictions.
%
%
%\section*{Theory}
%Materials have internal interactions. As physicists we like %
%to ignore these where possible but often these approximations %
%limit the accuracies of our models \citation. Magnetic %
%phenomenon are no different. To understand how spins interact %
%in a magnet it helps to first construct the simplest possible %
%model without interactions; a para-magnet.
%
%
%Consider our magnet as a one-dimensional chain of atomic spins. %
%For the moment ignore any external magnetic field and just %
%consider the spins in isolation. Now lets limit the spins to %
%be fixed up or down along one axis. If there are no interactions %
%between the spins the energy is fixed. If we add an external %
%magnetic field then we would expect the ensemble to develop a %
%net magnetisation.
%
%
%If the system has thermal energy we would expect some of the %
%spins to align themselves anti-parallel to the magnetic field. %
%We can see this affect by considering the partition function %
%for a single spin in the ensemble. If the spin is aligned with %
%the magnetic field then the energy is \(-sB\), where \(s\) is %
%the unit of magnetisation carried by the single spin and \(B\) %
%is the strength of the external magnetic field. If the spin is %
%anti-aligned with the field then the energy is \(sB\). 
%
%
%This is a simple two level system and the partition function %
%is given by, 
%%
%\begin{align}
%Z &= \sum_{s = \pm 1}\exp\left(-\frac{sB}{\tau}\right)\nonumber\\
%    &= \exp\left(-\frac{sB}{\tau}\right) + 
%        \exp\left(\frac{sB}{\tau}\right)\nonumber\\
%    &= 2\cosh\left(\frac{sB}{\tau}\right),
%\label{eqn:1}
%\end{align}
%%
%where, \(\tau = kT\) is the temperature in units of energy. %
%The probability of the spins being anti-aligned with the %
%field is therefore, 
%%
%\begin{align}
%P &= \frac{\exp\left(-\frac{sB}{\tau}\right)}
%        {2\cosh\left(\frac{sB}{\tau}\right)}.
%\label{eqn:2}
%\end{align}
%%
%Hence, as the temperature increase we expect the number of %
%anti-aligned spins to increase and as we increase the %
%magnetic field we expect the number of anti-aligned spins %
%to decrease. 
%
%
%Since each of the spins in a para-magnetic system is independent %
%the partition function of an ensemble of \(N\) spins is just %
%the product of \(N\) partition functions for the single spin %
%case. However, since the spins are indistinguishable we must %
%also divide by a Gibbs correction factor of \(N!\). %
%The probability of finding a particular state however, %
%is a case that is worth studying, since it indicates a %
%diveregence between the Ising model of a ferro-magnet and %
%a para-magnet in a magnetic field. First we need to define %
%our state. 
%
%
%The energy of the system, and any other physical %
%parameters, only depend on the number of spins that are %
%aligned with the magnetic field and not specifically %
%which spins are aligned with the field. Naively we might %
%expect that the probability of having \(N_{\uparrow}\) %
%spins aligned with the field would be,
%%
%\begin{align}
%P(N_{\uparrow}) &= \frac{
%        \exp\left(-\frac{sN_{\uparrow}B}{\tau}\right)
%        \exp\left(\frac{s(N - N_{\uparrow})B}{\tau}\right)}{
%        \cosh\left(\frac{sB}{\tau}\right)^{N}}.
%\label{eqn:3}
%\end{align}
%%
%However, equation \ref{eqn:3} has failed to account for the %
%multiple micro-states that occupy this macro-state. We can %
%account for this by multiplying by the multiplicity, which %
%can be found using the chose function,
%%
%\begin{align}
%P(N_{\uparrow}) &= \frac{N!}{N_{\uparrow}!(N - N_{\uparrow})!}
%        \frac{\exp\left(-\frac{sN_{\uparrow}B}{\tau}\right)
%        \exp\left(\frac{s(N - N_{\uparrow})B}{\tau}\right)}{
%        \cosh\left(\frac{sB}{\tau}\right)^{N}}.
%\label{eqn:4}
%\end{align}
%%
%Equation \ref{eqn:4} is the correct expression for the probability.
%
%
%It is informative to calculate the internal energy and free %
%energy of the system. Starting with the internal energy,
%%
%\begin{align}
%U &= \tau^{2}\partial_{\tau}\ln Z\nonumber\\
%    &= \tau^{2}\partial_{\tau}\ln\left(2^{N}\cosh^{N}
%        \left(\frac{sB}{\tau}\right)\right)\nonumber\\
%    &= -NsB\tanh\left(\frac{sB}{\tau}\right).
%\label{eqn:5}
%\end{align}
%%
%We can also calculate the free energy, but further calculations %
%result in tedious analytical expressions so we have omitted them. %
%%
%\begin{align}
%F &= -\tau\ln Z\nonumber\\
%    &= -\tau\ln\left(2^{N}\cosh^{N}\left(\frac{sB}{\tau}
%        \right)\right)\nonumber\\
%    &= -NsB - N\tau\ln\left(1 + \exp\left(-\frac{2sB}{\tau}\right)
%        \right).
%\label{eqn:7}
%\end{align}
%%
%As we will see when we analyse the Ising model without an external %
%field these results are general of any two level system. Using %
%equation \ref{eqn:5} we can calculate the magnetisation as a function %
%of the magnetic field and temperature, 
%%
%\begin{align}
%U = mB &= -NsB\tanh\left(\frac{sB}{\tau}\right)\nonumber\\
%    m &= -Ns\tanh\left(\frac{sB}{\tau}\right).
%\label{eqn:8}
%\end{align}
%%
%Therefore, the net magnetisation system will decrease with %
%temperature and increase with the magnetic field, much as we %
%would expect. 
%
%
%Para-magnets are a useful toy model but from our experience %
%with natural and manufactured magnets we know that it is %
%possibe to construct systems that are magnetic without external %
%fields. The one-dimensional Ising model is a simple model of %
%such systems. The Ising model is a natural extension of the %
%paramagnetic model that we discussed, and operates on the same %
%spin lattice. 
%
%
%The Ising model differs because it adds very simple interactions %
%between neighbouring spins. This interaction favours pairs that %
%are aligned by reducing the energy of this scenario. Representing %
%up spins as \(+1\) and down spins as \(-1\) we can represent this %
%mutal interaction as \(\Delta \epsilon = \varepsilon s_{i}s_{i + 1}\), %
%where \(\Delta \epsilon\) is the energy contribution of the %
%interaction, \(\varepsilon\) is a scaling factor that represents %
%the strength of the interaction and \(s_{i}\) is the \(i^{th}\) %
%spin in the chain. 
%
%
%
%
%What happens if we place the Ising model into an external magnetic %
%field. Again we can break it down by considering a single pair %
%in the chain as our constituent object. There are three energies %
%that it is possible for this pair to have; parallel and aligned %
%with the magnetic field, parallel and anti-aligned with the %
%magnetic field and anti-parallel. However, the final state has a %
%multiplicity of two since either of the spins could be aligned %
%with the field. 
%
%
%It is possible to compute the partition function for this the single %
%pair and hence also the entrie system.
%%
%\begin{align}
%Z_{1} &= \sum_{s}\exp\left(-\frac{\epsilon_{s}}{\tau}\right)
%        \nonumber\\
%    &= \exp\left(\frac{-\epsilon - 2B}{\tau}\right) +
%        2\exp\left(\frac{\epsilon}{\tau}\right) +
%        \exp\left(\frac{-\epsilon + 2B}{\tau}\right)
%        \nonumber\\
%    &= 2\exp\left(\frac{-\epsilon}{\tau}\right)
%        \cosh\left(\frac{2B}{\tau}\right) + 
%        2\exp\left(\frac{\epsilon}{\tau}\right).
%\label{eqn:14}
%\end{align}
%%
%From here we can compute all the physical properties of the system. %
%Since each pair is independent the partition function is simply the %
%product of \(N\) partition function by the same reasoning as in %
%the case above when there was no magnetic field. We have not shown %
%the calculation of the energy ect., because the expressions are %
%complex and uninformative. 
%
%
%Another interesting effect that can be explored using the Ising model %
%is anti-ferro-magnetism. This phenomenon was only recently discovered %
%in nature \citation and refers to and interaction between neighbouring %
%spins that causes them to have lower energy when they are aligned %
%anti-parallel rather than parallel. We do not need to cover any new %
%equations in this case as an anti-ferro-magnet can be explored by %
%letting \(\epsilon\) become negative. 
%
%
%We have spent a lot of time discussing the one-dimensional scenario %
%but real systems are typically higher dimensional. There is a %
%an analytical solution to the two-dimensional ising model \citation. %
%This solution is a tour de force and has comparatively little %
%practical use due to its complexity. Multiple approximation methods %
%have been developed for dealing with the two-dimensional case, %
%most notably the mean field approximation. 
%
%
%The mean field approximation treats a group of neighbours as an %
%a single spin, parametrised by the mean. In this way we recover %
%the two level system and arrive at a two level system that is %
%very similar to what we have already covered for the para-magnet %
%and the Ising model when there is no external magnetic field. %
%Ultimately the mean field approximation is an approximation and %
%its predictions are not always correct. 
%
%
%Another aspect of higher dimensions that it is worth discussing %
%is what counts as a neighbour. For example, in two-dimensions %
%we could connet the spins together so that each spins is equally %
%far from six other spins. This triangular Ising model will have %
%markedly different behaviour than a square grid of spins \citation. %
%For our analysis we have considered a square grid of spins since %
%it is simpler to simulate. 
%
%
%Without going into the complex analytical solutions we can still %
%make useful qualitative guesses about the behaviour of the Ising %
%model in higher dimensions based on its behaviour in lower %
%dimensions. For example, we expect the spins will tend to align %
%at lower temperatures and tend to disorder at higher temperatures. %
%For the anti-ferro-magnetic case we expect the spins to become %
%anti-aligned at low temperatures and tend to disorder at higher %
%temperatures.
%
%
%It is worth noting that in the presence of a magnetic field the %
%qualitative behaviour of the anti-ferro-magnetic and ferro-magnetic %
%Ising models becomes markedly different. The ferro-magnetic model %
%results in a positive feedback loop as the magnetic field coerces %
%spins to align with the field they also want to align with each other.
%On the other hand the anti-ferro-magnet exerts a dampening effect %
%for the opposite reason. 
%
%
%\section*{Method}
%\begin{verbatim}
%function calc_energy
%energy = 0
%for spin in 0:length
%energy += ensemble[spin] * ensemble[spin + 1]
%return energy
%\end{verbatim}
%
%
%Similarly for the entropy we counted all of the aligned pairs. %
%This works because as discussed in the theory the "base unit" %
%of the Ising model is a pair of spins not an individual spin. %
%As noted in the Theory there are \(N\) pairs of spins. Moreover, %
%we ued Stirling's approximation in the logarithmic form, because %
%we found that the program could not calculate numbers of the size %
%\(100!\). This will have had negligible affects at higher %
%temperatures where the system tends torward disorder, but at %
%lower temperatures the approximation becomes less accurate. %
%We were not too concerned with the loss of accuracy since the %
%entropy tends to zero at low temperatures.
%%
%\begin{verbatim}
%function calc_entropy
%up = 0
%for spin in 0:length
%up += ensemble[spin] == ensemble[spin + 1]
%down = length - up
%entropy = length * log(length) - up * log(up) - down * log(down)
%return entropy
%\end{verbatim}
%
%
%The free energy was calculated using its definition, \(F = U - %
%\tau\sigma\), where \(\tau = kT\) and \(\sigma\) is the entropy. %
%The heat capacity was calculated using the thermodynamic %
%identity,
%%
%\begin{align}
%C_{V} &= \frac{\textrm{var(U)}{\tau^{2}}}.
%\label{eqn:15}
%\end{align}
%%
%A large part of the computational expense came from estimating the %
%uncertainty in the physical parameters. It did not make sense to %
%initialise the system randomly at every temperature and then wait %
%for it to equilibrate before taking measurements. Instead we %
%initialised the system at a high temperature where the random %
%configuration is a good approximation to the equilibrium %
%configuration and equilibrated it. 
%
%
%From this higher temperature %
%we allowed the system to evolve for \(1000N\) steps measuring %
%the physical properties at every step. We then cooled the system %
%by a small incremement and without re-equilibrating the system %
%evolved it for \(1000N\) steps taking measurements every step. %
%In this way we halved the amount of CPU time required by each run %
%but introduced a small error by starting the system at a slightly %
%out of equilibrium state. Given the large number of runs we believe %
%that this error is negligible, although it is visible at lower %
%temperatures as the heat capacity becomes over-estiamted. 
%
%
%Another flaw of running the simulation this way was that it %
%serialised the loops (i.e. made the next iteration depend on the %
%state of the previous one). This prevented us from making efficient %
%parallelisation of the inner loop, however, the outer loop was %
%not serial and could be efficiently paralellised. After each run %
%of \(1000N\) the average was taken for each physical parameter. 
%
%
%
%Please note that we did not use the standard error of the %
%\(1000N\) trials as the error. It does not make sense to do %
%so because each state is deterministically dependent on the %
%previous one and the sample gridding is much too fine. Instead %
%we repeated the entire process a fixed number of times \(100\) for %
%the one-dimensional case and used the standard error of the means %
%from these 100 trials as the estimate of our uncertainty. Note that %
%we defined the standard error as \(\sqrt{\textrm{Var}{N}}\). %
%
%
%We noticed that the infinite one-dimensional Ising model is predicted %
%to have no net magnetisation at \(0K\). To test this hypothesis, %
%we created histograms of the magnetisation at \(\tau = 0.5J, 1.0J\) %
%and \(2.0J\) for \(N = 100\) and \(N = 500\). We expected the %
%histograms to be narrower as the number of spins in the system was %
%increased.
%
%
%Once we were satisfied with the one-dimensional ising model we %
%repeated a similar analysis for the two-dimensional model. %
%First we tested the time required for equilibration by initialising %
%the model and running it for \(1000N^{2}\) where \(N\) is the width %
%of the grid. 
%
%
%Satisfied with the equilibration time we employed the same techniques %
%described for the one-dimensional case to the two-dimensional case %
%to measure the physical parameters. In short, we incrementally cooled %
%the system measuring every iteration and recording the mean. We %
%repeated this process a fixed number of times and used the standard %
%error as our uncertainty estimate. The energy calculation is %
%clearly modified, so we have included the relevant pseudocode %
%below:
%%
%
%
%\section*{Results}
%We noticed that the net magnetisation set in at lower temperatures for %
%the larger \(N\). This tells us that there is no phase transition %
%because a phase transition should occur at exactly the same %
%temperature for all latice sizes. Moreover, it agrees with the %
%theoretical prediction that the Ising model is not magnetised at %
%\(0K\) in the infinite case because it we increase the latticed %
%temperature to infinity then the temperature of net magnetisation %
%should decrease below \(0K\). 
\end{document}
